{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def plot_shaps(shap_values, data, dataset: str, analysis: str, plot_type: str = 'dot'):\n",
    "    sns.set(\"paper\", font_scale=0.1)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5), dpi=150)\n",
    "    plt.sca(ax)\n",
    "\n",
    "    shap.summary_plot(\n",
    "        shap_values, data, show=False, max_display=20, plot_size=None, feature_names=columns, plot_type=plot_type\n",
    "    )\n",
    "    if analysis == 'central':\n",
    "        plt.title('Centralized')\n",
    "    elif analysis == 'federated-analysis':\n",
    "        plt.title('Federated')\n",
    "    elif analysis == 'smpc-analysis':\n",
    "        plt.title('SMPC')\n",
    "    else:\n",
    "        raise Exception('Invalid analysis')\n",
    "\n",
    "    plt.title('dataset')\n",
    "\n",
    "    val = None\n",
    "    if dataset == 'brca':\n",
    "        val = 40\n",
    "    elif dataset == 'gbsg2':\n",
    "        val = 75\n",
    "    elif dataset == 'whas500':\n",
    "        val = 40\n",
    "    elif dataset == 'microbiome':\n",
    "        val = 4\n",
    "\n",
    "    if plot_type == 'dot':\n",
    "        ax.set_xlim(-val, val)\n",
    "    elif plot_type == 'bar':\n",
    "        ax.set_xlim(0, val / 2)\n",
    "    else:\n",
    "        raise Exception('Invalid dataset')\n",
    "    fig.savefig(f'{dataset}/{analysis}_{plot_type}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for dataset in ['brca',\n",
    "                'gbsg2',\n",
    "                'whas500',\n",
    "                'microbiome'\n",
    "                ]:\n",
    "    print(dataset)\n",
    "    os.makedirs(f'{dataset}', exist_ok=True)\n",
    "    shaps = []\n",
    "    for analysis in ['central', 'federated-analysis', 'smpc-analysis']:\n",
    "        print(analysis)\n",
    "        if analysis == 'central':\n",
    "            data = pd.read_csv(f'../central/{dataset}/data.csv').drop(columns=['event', 'tte'])\n",
    "            columns = data.columns.tolist()\n",
    "            data = pd.DataFrame(StandardScaler().fit_transform(data))\n",
    "\n",
    "            with open(f'../central/{dataset}/model.pkl', 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "        elif analysis == 'federated-analysis':\n",
    "            train = pd.read_csv(\n",
    "                f'../{analysis}/{dataset}/1_clients/fc_normalization/client_1/data/split_1/train_norm.csv')\n",
    "            test = pd.read_csv(\n",
    "                f'../{analysis}/{dataset}/1_clients/fc_normalization/client_1/data/split_1/test_norm.csv')\n",
    "            data = pd.concat([train, test]).drop(columns=['event', 'tte'])\n",
    "            columns = data.columns.tolist()\n",
    "            data = data.to_numpy()\n",
    "            with open(f'../{analysis}/{dataset}/3_clients/fc_normalization/fc_survival_svm/client_1/model.pickle',\n",
    "                      'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "        elif analysis == 'smpc-analysis':\n",
    "            train_client_1 = pd.read_csv(\n",
    "                f'../{analysis}/{dataset}/5_clients/basic_normalization/client_1/data/split_1/train_norm.csv')\n",
    "            test_client_1 = pd.read_csv(\n",
    "                f'../{analysis}/{dataset}/5_clients/basic_normalization/client_1/data/split_1/test_norm.csv')\n",
    "            train_client_2 = pd.read_csv(\n",
    "                f'../{analysis}/{dataset}/5_clients/basic_normalization/client_2/data/split_1/train_norm.csv')\n",
    "            test_client_2 = pd.read_csv(\n",
    "                f'../{analysis}/{dataset}/5_clients/basic_normalization/client_2/data/split_1/test_norm.csv')\n",
    "            train_client_3 = pd.read_csv(\n",
    "                f'../{analysis}/{dataset}/5_clients/basic_normalization/client_3/data/split_1/train_norm.csv')\n",
    "            test_client_3 = pd.read_csv(\n",
    "                f'../{analysis}/{dataset}/5_clients/basic_normalization/client_3/data/split_1/test_norm.csv')\n",
    "            data = pd.concat(\n",
    "                [train_client_1, test_client_1, train_client_2, test_client_2, train_client_3, test_client_3]).drop(\n",
    "                columns=['event', 'tte'])\n",
    "            columns = data.columns.tolist()\n",
    "            data = data.to_numpy()\n",
    "            with open(f'../{analysis}/{dataset}/5_clients/basic_normalization/fc_survival_svm/client_1/model.pickle',\n",
    "                      'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "        else:\n",
    "            raise Exception('Invalid analysis')\n",
    "\n",
    "        explainer = shap.Explainer(model.predict, data, feature_names=columns, seed=np.random.seed(231211),\n",
    "                                   algorithm='auto')\n",
    "        shap_values = explainer(data, max_evals=5000)\n",
    "\n",
    "        plot_shaps(shap_values, data, dataset, analysis, plot_type='dot')\n",
    "        plot_shaps(shap_values, data, dataset, analysis, plot_type='bar')\n",
    "\n",
    "        shap_series = pd.DataFrame(shap_values.values, columns=columns).abs().mean(axis=0).sort_index()\n",
    "        shap_series.to_csv(f'{dataset}/{analysis}_shap.csv')\n",
    "        shaps.append(shap_series)\n",
    "\n",
    "    for corr_type in ['pearson']:\n",
    "        corr_central_vs_fed = shaps[0].corr(shaps[1], method=corr_type)\n",
    "        corr_central_vs_smpc = shaps[0].corr(shaps[2], method=corr_type)\n",
    "        corr_fed_vs_smpc = shaps[1].corr(shaps[2], method=corr_type)\n",
    "\n",
    "        corr_df = pd.DataFrame(np.nan, index=['central', 'federated', 'federated + secure aggregation'],\n",
    "                               columns=['central', 'federated', 'federated + secure aggregation'])\n",
    "        corr_df.loc['central', 'central'] = 1\n",
    "        corr_df.loc['central', 'federated'] = corr_central_vs_fed\n",
    "        corr_df.loc['central', 'federated + secure aggregation'] = corr_central_vs_smpc\n",
    "        corr_df.loc['federated', 'central'] = corr_central_vs_fed\n",
    "        corr_df.loc['federated', 'federated'] = 1\n",
    "        corr_df.loc['federated', 'federated + secure aggregation'] = corr_fed_vs_smpc\n",
    "        corr_df.loc['federated + secure aggregation', 'central'] = corr_central_vs_smpc\n",
    "        corr_df.loc['federated + secure aggregation', 'federated'] = corr_fed_vs_smpc\n",
    "        corr_df.loc['federated + secure aggregation', 'federated + secure aggregation'] = 1\n",
    "        corr_df.to_csv(f'results/{dataset}/shap_{corr_type}.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b084a0c36855ef4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for dataset in ['brca', 'gbsg2', 'microbiome', 'whas500']:\n",
    "    df = pd.read_csv(f'results/{dataset}/shap_pearson.csv')\n",
    "    df['dataset'] = dataset\n",
    "    df = df.rename(columns={'Unnamed: 0': 'type'})\n",
    "    dfs.append(df)\n",
    "    \n",
    "df = pd.concat(dfs)\n",
    "df.to_csv('xai.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbb19898cb79f59",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a4dff252a33a860"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
